{
    "timestamp": "2025-09-27 01:21:43",
    "config": {
        "DATA_PATH_TRAIN": "./data/match_data_4030611.csv",
        "DATA_PATH_TEST": "./data/labeled_data.csv",
        "BERT_MODEL_NAME": "HooshvareLab/bert-fa-base-uncased",
        "MAX_LEN": 64,
        "BATCH_SIZE": 8,
        "BERT_EPOCHS": 2,
        "LEARNING_RATE": 1e-05,
        "ENSEMBLE_WEIGHTS": {
            "bert": 2.0,
            "svm": 1.0,
            "logreg": 1.0,
            "fasttext": 1.0
        },
        "GPU_USAGE_LIMIT": 0.7,
        "SVM_C": 1.0,
        "LOGREG_C": 1.0,
        "FASTTEXT_EPOCHS": 100,
        "FASTTEXT_LR": 0.1,
        "FASTTEXT_WORDNGRAMS": 5
    },
    "individual_model_results": {
        "bert": {
            "accuracy": 0.5134328358208955,
            "precision": 0.6258728706659751,
            "recall": 0.5972738674118242,
            "f1_score": 0.5054099015640457
        },
        "svm": {
            "accuracy": 0.5127694859038142,
            "precision": 0.6223994273653659,
            "recall": 0.5955327854346056,
            "f1_score": 0.5051550503784824
        },
        "logreg": {
            "accuracy": 0.5270315091210613,
            "precision": 0.6293317301903313,
            "recall": 0.6058336290940538,
            "f1_score": 0.5215402003317198
        },
        "fasttext": {
            "accuracy": 0.5485903814262023,
            "precision": 0.6235987110799395,
            "recall": 0.613458037532753,
            "f1_score": 0.547184446349101
        }
    },
    "ensemble_results": {
        "accuracy": 0.5227197346600332,
        "precision": 0.6336472319025822,
        "recall": 0.6053287631525829,
        "f1_score": 0.5156601634186522
    }
}